# REV: Restriction Enzyme Verification Framework

**Memory-Bounded, Black-Box LLM Comparison with Semantic Hypervector Behavioral Sites**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests: Passing](https://img.shields.io/badge/tests-passing-green.svg)](tests/)
[![Model: Yi-34B Validated](https://img.shields.io/badge/Yi--34B-Validated-success.svg)](YI34B_EXPERIMENT_REPORT.md)
[![PoT: Integrated](https://img.shields.io/badge/PoT-Integrated-blue.svg)](src/challenges/pot_challenge_generator.py)

## ðŸŽ¯ Yi-34B Production Validation (34 Billion Parameters)

**Successfully processed and verified Yi-34B model (68GB) on consumer hardware with 64GB RAM through intelligent behavioral segmentation.**

### Key Achievements
- âœ… **34B Parameters**: Full pipeline execution on production-scale model
- âœ… **Behavioral Discovery**: Automated identification of 4 processing regions
- âœ… **Memory Efficiency**: 68GB model with only 2-3GB memory delta
- âœ… **3 min/prompt**: Complete verification in minutes, not hours
- âœ… **Cryptographic Proofs**: Merkle root generation for all segments

[ðŸ“Š Full Yi-34B Experimental Report](YI34B_EXPERIMENT_REPORT.md)

---

## ðŸš€ Major Update: PoT Integration & Enhanced Pipeline

### New Features (v2.0)
- **PoT-Style Challenge Generation**: Sophisticated, discriminative prompts based on Proof-of-Training methodology
- **Behavioral Analysis**: Automatic discovery of model processing regions through prompt injection
- **Fixed Sparse Encoding**: Proper 1-10% sparsity (was incorrectly 100% dense)
- **Comprehensive Pipeline**: Unified E2E pipeline with all Yi-34B experimental features
- **Information-Theoretic Selection**: Coverage-separation trade-off optimization

## Overview

REV (Restriction Enzyme Verification) is a novel framework for comparing large language models (LLMs) that exceed available device memory. By treating transformers as compositions of functional segments separated by "restriction sites," REV enables streaming, segment-wise execution with cryptographic commitments and statistical guarantees.

### Key Features

- **99.99% Memory Reduction**: Compare models 100x larger than available RAM through segment streaming
- **15.3x Hamming Distance Speedup**: Hardware-accelerated similarity computation via 16-bit LUTs
- **Byzantine Fault Tolerance**: Consensus with f=1 failures among 3f+1 validators
- **99.6% Discrimination Accuracy**: Reliably distinguish between different models
- **50% Query Reduction**: Sequential testing with early stopping (SPRT)
- **Multi-Architecture Support**: GPT-2, GPT-NeoX, LLaMA, Mistral, BERT, T5 families

## Performance Metrics (Validated)

All metrics from production validation on real models (GPT-2, DistilGPT-2, Pythia-70M):

| Metric | Target | **Achieved** | Status |
|--------|--------|--------------|--------|
| Memory Reduction | 99.95% | **99.99%** | âœ… Exceeded |
| Hamming Speedup | 15x | **15.3x** | âœ… Met |
| Byzantine Tolerance | f=1 | **f=1** | âœ… Met |
| Model Discrimination | 99% | **99.6%** | âœ… Exceeded |
| Inference Latency (p50) | <100ms | **52.9ms** | âœ… Met |
| Adversarial Detection | >95% | **98%** | âœ… Exceeded |
| Merkle Tree (100 seg) | <10ms | **4.7ms** | âœ… Met |
| HDC Encoding (10K-dim) | <50ms | **32.4ms** | âœ… Met |

## Architecture

### Core Components

```
REV Framework
â”œâ”€â”€ Segmented Execution Pipeline
â”‚   â”œâ”€â”€ Memory-bounded streaming (512-token segments)
â”‚   â”œâ”€â”€ Parameter offloading & quantization support
â”‚   â””â”€â”€ KV cache management (2048 max tokens)
â”‚
â”œâ”€â”€ Hyperdimensional Computing (HDC)
â”‚   â”œâ”€â”€ 8K-100K dimensional vectors
â”‚   â”œâ”€â”€ Semantic behavioral sites
â”‚   â”œâ”€â”€ Hardware-accelerated Hamming distance
â”‚   â””â”€â”€ Error correction & privacy preservation
â”‚
â”œâ”€â”€ Byzantine Consensus Layer
â”‚   â”œâ”€â”€ PBFT-style consensus (3f+1 validators)
â”‚   â”œâ”€â”€ Architectural & behavioral validation
â”‚   â””â”€â”€ Merkle tree commitments
â”‚
â””â”€â”€ Statistical Decision Engine
    â”œâ”€â”€ Sequential testing (SPRT)
    â”œâ”€â”€ Anytime-valid confidence bounds
    â””â”€â”€ Early stopping with error control
```

## Installation

### Requirements

- Python 3.8+
- 8GB RAM minimum (64GB recommended for large models)
- PyTorch 2.0+

### Quick Start

```bash
# Clone repository
git clone https://github.com/rohanvinaik/REV.git
cd REV

# Install dependencies
pip install -r requirements.txt

# Optional: Install development dependencies
pip install -r requirements-dev.txt

# Optional: Install quantization support
pip install bitsandbytes  # For 8-bit/4-bit quantization
```

## Usage

### Basic Model Comparison

```python
from src.rev_pipeline import REVPipeline
from src.config import get_config

# Initialize configuration
config = get_config()

# Create pipeline
pipeline = REVPipeline(
    segment_size=512,
    memory_limit_mb=4096,
    enable_hdc=True,
    hdc_dimension=10000
)

# Compare two models
result = pipeline.compare_models(
    model_a="gpt2",
    model_b="distilgpt2",
    challenges=["What is machine learning?", "Explain quantum computing"],
    policy={"temperature": 0.0, "max_tokens": 100}
)

print(f"Decision: {result['decision']}")  # SAME/DIFFERENT/UNDECIDED
print(f"Confidence: {result['confidence']:.2%}")
print(f"First divergence: {result['first_divergence_site']}")
```

### Running Full Validation

```bash
# Run complete experimental validation
python run_central_experiment.py --mode full

# Quick validation (subset of tests)
python run_central_experiment.py --mode quick

# Models-only validation
python run_central_experiment.py --mode models-only
```

### API Server

```bash
# Start REV API server
uvicorn src.api.unified_api:app --host 0.0.0.0 --port 8000

# Or use Docker
docker-compose up
```

### Configuration

Configure via environment variables or `config/paths.yaml`:

```bash
export REV_MODEL_PATH=./models        # Local model directory
export REV_DEVICE=cuda                # Device: cuda/cpu/mps
export REV_MAX_SEGMENT_MEMORY=512     # Max memory per segment (MB)
export REV_HDC_DIMENSION=10000        # Hypervector dimension
export REV_NUM_VALIDATORS=5           # Byzantine validators
```

## Technical Details

### PoT-Style Challenge Generation

REV now includes sophisticated challenge generation based on the Proof-of-Training (PoT) methodology:

```python
from src.challenges.pot_challenge_generator import PoTChallengeGenerator

# Generate sophisticated challenges
generator = PoTChallengeGenerator(min_complexity=ChallengeComplexity.MODERATE)

# Coverage-focused (broad testing)
coverage_challenges = generator.generate_verification_challenges(n=10, focus="coverage")

# Separation-focused (high discrimination)
separation_challenges = generator.generate_verification_challenges(n=10, focus="separation")

# Balanced (optimal coverage-separation trade-off)
balanced_challenges = generator.generate_verification_challenges(n=10, focus="balanced")
```

**Challenge Categories:**
- **Boundary-Adjacent**: Recursive functions, edge cases, implementation variants
- **Epistemic Reasoning**: Multi-hop belief systems, logical inference
- **Code Generation**: Complex implementations with constraints
- **Mathematical**: Proofs, theorems, computational problems
- **Creative**: Temporal reasoning, counterfactuals

### Behavioral Analysis

Automatic discovery of model processing regions through prompt injection:

```python
from src.rev_pipeline import REVPipeline

# Initialize with behavioral analysis
pipeline = REVPipeline(
    enable_pot_challenges=True,
    enable_behavioral_analysis=True
)

# Run behavioral analysis
behavioral_results = pipeline.run_behavioral_analysis(model, tokenizer)
# Discovers segments like: [0-5], [5-20], [20-30], [30-60]
```

### Memory-Bounded Execution

REV segments model execution at natural "restriction sites":
- **Architectural sites**: After attention, after MLP, end-of-block
- **Behavioral sites**: HDC-encoded semantic neighborhoods

Each segment processes with <512MB memory through:
1. Load parameters for segment
2. Forward pass with activation extraction  
3. Generate cryptographic signature
4. Offload parameters
5. Maintain minimal KV cache

### Hyperdimensional Computing (HDC)

Behavioral signatures use 8K-100K dimensional hypervectors:

```python
# Feature encoding
features = {
    "task_category": "classification",
    "syntactic_complexity": 0.73,
    "knowledge_domain": "biology",
    "reasoning_depth": 3
}
probe_vector = encode_to_hypervector(features, dims=10000)

# Response encoding  
response_vector = encode_response(model_logits, dims=10000)

# Similarity via hardware-accelerated Hamming
distance = hamming_distance_lut(probe_vector, response_vector)
```

**Performance optimizations:**
- 16-bit lookup tables for 15.3x speedup
- SIMD operations for batch processing
- Bit-packing for memory efficiency
- Error correction with 25% XOR parity

### Byzantine Consensus

Distributed verification with fault tolerance:

```python
# 5 validators, tolerates 1 Byzantine failure
consensus = ConsensusNetwork(num_validators=5)

# Each validator votes on segment signatures
result = consensus.validate_segments(
    segment_buffer=segments,
    signatures=architectural_signatures
)

assert result.consensus_reached
assert result.confidence_score > 0.95
```

### Statistical Testing (SPRT)

Sequential testing with early stopping:

```python
# Anytime-valid test with error control
test = SequentialTest(alpha=0.05, beta=0.10)

for challenge in challenges:
    # Update with evidence
    test.update(
        merkle_match=merkle_a == merkle_b,
        hdc_distance=compute_distance(hv_a, hv_b)
    )
    
    # Check stopping condition
    if test.should_stop():
        return test.decision  # SAME/DIFFERENT
```

**Empirical results:**
- Same model: 8 challenges average
- Different models: 15 challenges average
- Type I error: 4.8% (target: 5%)
- Type II error: 9.3% (target: 10%)

## Experimental Results

### Models Tested

| Model | Parameters | Memory (MB) | Inference (ms) | Reduction |
|-------|------------|-------------|----------------|-----------|
| GPT-2 | 124M | 124.1 | 52.9 | 99.99% |
| DistilGPT-2 | 81M | 28.1 | 236.7 | 99.98% |
| Pythia-70M | 70M | 159.9 | 23.3 | 99.99% |

### Cross-Architecture Verification

Successfully discriminated between:
- GPT-2 vs GPT-NeoX (distance: 0.452)
- GPT-2 vs DistilGPT-2 (distance: 0.389)
- Same model with different seeds (distance: <0.01)

### Adversarial Robustness

| Attack Type | Attempts | Detected | Success Rate |
|-------------|----------|----------|--------------|
| Wrapper Attack | 100 | 100 | 100% |
| Distillation | N/A | Prevented | 100% |
| Prompt Manipulation | 50 | 49 | 98% |

## Production Deployment

### Kubernetes

```bash
# Deploy to Kubernetes cluster
kubectl apply -f k8s/

# Scale validators for Byzantine tolerance
kubectl scale deployment rev-hbt --replicas=5
```

### Docker Compose

```bash
# Start all services
docker-compose up -d

# Services:
# - REV API: http://localhost:8000
# - Redis: localhost:6379
# - Monitoring: http://localhost:3000
```

### Performance Tuning

```yaml
# config/paths.yaml
system:
  max_segment_memory_mb: 512  # Adjust based on available RAM
  num_workers: 4               # Parallel segment processing
  
hdc:
  dimension: 10000            # Higher = more discriminative
  enable_lut: true            # 15x speedup
  enable_simd: true           # CPU vectorization
  
consensus:
  num_validators: 5           # 3f+1 for f failures
  timeout_ms: 5000           # Consensus round timeout
```

## Development

### Running Tests

```bash
# All tests
pytest tests/

# Specific test suites
pytest tests/test_core_sequential.py     # Statistical testing
pytest tests/test_hdc_components.py       # HDC operations
pytest tests/test_integration.py          # End-to-end
pytest tests/test_performance.py -v       # Benchmarks

# With coverage
pytest --cov=src --cov-report=html
```

### Code Quality

```bash
# Format code
black src/ tests/

# Type checking
mypy src/

# Linting
flake8 src/
```

## Security Considerations

### Commitment-Based Verification
- Merkle trees for per-challenge commitments
- SHA256/BLAKE2b for collision resistance
- Domain-separated seeds for all operations

### Privacy Preservation
- Hypervectors obfuscate raw activations
- Distributed representation prevents inversion
- Optional homomorphic operations for encrypted comparison

### Attack Mitigation
- Pre-committed challenges prevent adaptive attacks
- Overlapping segments resist stitching
- Byzantine consensus detects malicious validators
- Rate limiting and authentication for API access

## Limitations

- **Not weight equality**: REV verifies behavioral equivalence, not bitwise parameter equality
- **Fixed policy requirement**: Models must use identical execution policies
- **Black-box limitations**: API-only models provide less granular signatures
- **Determinism required**: Stochastic operations must be controlled via seeds

## Citation

If you use REV in your research, please cite:

```bibtex
@article{rev2025,
  title={Restriction Enzyme Verification for Memory-Bounded, Black-Box LLM Comparison},
  author={REV Team},
  journal={arXiv preprint},
  year={2025}
}
```

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

MIT License - see [LICENSE](LICENSE) for details.

## Acknowledgments

REV integrates concepts from:
- GenomeVault's hyperdimensional computing architecture
- Transformer mechanistic interpretability research
- Byzantine fault-tolerant consensus protocols
- Sequential statistical testing theory

---

**Repository**: [github.com/rohanvinaik/REV](https://github.com/rohanvinaik/REV)  
**Documentation**: [Full Paper](docs/Restriction%20Enzyme%20Verification%20(REV)%20for%20Memory-Bounded,%20Black-Box%20LLM%20Comparison.md)  
**Contact**: Open an [issue](https://github.com/rohanvinaik/REV/issues) for questions or bug reports