# REV - Restriction Enzyme Verification

A framework for memory-bounded, black-box LLM comparison using restriction enzyme verification techniques combined with hyperdimensional computing and privacy-preserving infrastructure.

## Overview

REV (Restriction Enzyme Verification) provides a comprehensive framework for comparing and verifying Large Language Models (LLMs) under memory-bounded constraints. The system combines cutting-edge techniques from statistical testing, hyperdimensional computing, and cryptography to enable efficient and privacy-preserving model verification.

## Key Features

### ðŸ§¬ Sequential Testing Framework
- **Anytime-valid statistical tests** with Empirical-Bernstein bounds
- **SPRT (Sequential Probability Ratio Test)** implementation with numerical stability
- **Welford's algorithm** for online mean/variance computation
- **Early stopping** with configurable error bounds (Î±, Î²)

### ðŸŽ¯ Challenge Generation
- **Deterministic prompt generation** with seeded synthesis
- **Reproducible probes** for consistent model evaluation
- **Domain-specific challenge templates** with variable difficulty
- **Commit-reveal protocols** for verification integrity

### ðŸ”¬ Model Verification Pipeline
- **Enhanced sequential testing** with streaming execution
- **Verdict system** with confidence intervals
- **Adaptive sampling** based on statistical power
- **Resource-bounded verification** for memory efficiency

### ðŸ§  Hyperdimensional Computing Core
- **8K-100K dimensional vectors** for model signatures
- **Sparse and dense encoding** strategies
- **Orthogonal random projections** for dimensionality preservation
- **Numerical stability** with fp32/fp64 precision control

### âš¡ Hamming Distance LUTs
- **16-bit lookup tables** for 10-20Ã— speedup
- **Batch processing** with vectorized operations
- **CPU/GPU acceleration** support
- **Memory-efficient packed binary representations**

### ðŸ”’ Privacy-Preserving Infrastructure
- **Zero-knowledge proofs** using Halo2-compatible circuits
- **Differential privacy** mechanisms with calibrated noise
- **Merkle tree commitments** for verifiable computation
- **No trusted setup** required for ZK verification

## Installation

### Requirements
- Python 3.8+
- NumPy, PyTorch, Transformers
- Cryptography libraries (pycryptodome)
- Optional: CUDA for GPU acceleration

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/REV.git
cd REV

# Install dependencies
pip install -r requirements.txt

# Optional: Install development dependencies
pip install -e ".[dev]"
```

## Quick Start

### Basic Verification

```python
from rev import sequential_verify, DeterministicPromptGenerator

# Generate challenges
generator = DeterministicPromptGenerator(seed=42)
challenges = generator.generate_batch(n=100)

# Run sequential verification
result = sequential_verify(
    model_a=model_a,
    model_b=model_b,
    challenges=challenges,
    alpha=0.05,
    beta=0.10
)

print(f"Decision: {result.decision}")
print(f"Confidence: {result.confidence:.3f}")
```

### Hyperdimensional Encoding

```python
from rev import HypervectorEncoder, HypervectorConfig

# Configure encoder
config = HypervectorConfig(
    dimension=10000,
    sparse_density=0.01,
    dtype="float32"
)

# Encode model outputs
encoder = HypervectorEncoder(config)
signature = encoder.encode_sequence(model_outputs)
```

### Privacy-Preserving Verification

```python
from rev import ZKProofSystem, DifferentialPrivacyMechanism

# Setup zero-knowledge proof
zk_system = ZKProofSystem()
proof = zk_system.prove_verification(result)

# Add differential privacy
dp_mechanism = DifferentialPrivacyMechanism(epsilon=1.0)
private_result = dp_mechanism.privatize(result)
```

## Architecture

```
src/
â”œâ”€â”€ core/                 # Core statistical testing
â”‚   â”œâ”€â”€ sequential.py     # SPRT and sequential testing
â”‚   â”œâ”€â”€ boundaries.py     # Empirical-Bernstein bounds
â”‚   â””â”€â”€ stats.py          # Statistical utilities
â”œâ”€â”€ challenges/           # Challenge generation
â”‚   â”œâ”€â”€ prompt_generator.py
â”‚   â””â”€â”€ templates.py
â”œâ”€â”€ verifier/            # Model verification
â”‚   â”œâ”€â”€ decision.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ hdc/                 # Hyperdimensional computing
â”‚   â”œâ”€â”€ encoder.py
â”‚   â””â”€â”€ projections.py
â”œâ”€â”€ hypervector/         # Hypervector operations
â”‚   â”œâ”€â”€ hamming.py       # Hamming distance
â”‚   â”œâ”€â”€ operations/      # Vector operations
â”‚   â””â”€â”€ packed.py        # Packed representations
â”œâ”€â”€ crypto/              # Cryptographic primitives
â”‚   â”œâ”€â”€ zk_proofs.py     # Zero-knowledge proofs
â”‚   â”œâ”€â”€ merkle.py        # Merkle trees
â”‚   â””â”€â”€ commit.py        # Commitment schemes
â””â”€â”€ privacy/             # Privacy mechanisms
    â””â”€â”€ differential_privacy.py
```

## Performance

### Benchmarks

| Component | Operation | Performance |
|-----------|-----------|-------------|
| Hamming LUT | 10K-dim distance | 10-20Ã— faster than naive |
| HDC Encoder | 100K-dim encoding | ~50ms per sample |
| Sequential Test | 1000 samples | <100ms decision |
| ZK Proof | Generation | ~200ms |
| Merkle Tree | 1M leaves | ~1s construction |

### Memory Usage

- **Hypervectors**: 40KB for 10K-dim float32
- **Hamming LUT**: 512KB for 16-bit table
- **ZK Circuits**: ~10MB compiled
- **Merkle Proofs**: O(log n) storage

## Advanced Usage

### Custom Challenge Templates

```python
from rev.challenges import ChallengeTemplate

template = ChallengeTemplate(
    pattern="Complete the sequence: {prefix}",
    difficulty="hard",
    domain="mathematical"
)

challenges = generator.generate_from_template(template, n=50)
```

### Streaming Verification

```python
from rev.verifier import StreamingVerifier

verifier = StreamingVerifier(buffer_size=32)
for batch in data_stream:
    decision = verifier.update(batch)
    if decision.is_conclusive:
        break
```

### GPU Acceleration

```python
from rev.hypervector import hamming_distance_gpu

# Compute on GPU if available
import torch
if torch.cuda.is_available():
    distance = hamming_distance_gpu(vec_a, vec_b)
```

## Components Origin

This framework integrates battle-tested components from:

- **PoT_Experiments**: Sequential testing, challenge generation, and model verification pipeline
- **GenomeVault**: Hyperdimensional computing, Hamming distance LUTs, and privacy-preserving infrastructure

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Install dev dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black src/ tests/

# Type checking
mypy src/
```

## Citation

If you use REV in your research, please cite:

```bibtex
@software{rev2024,
  title = {REV: Restriction Enzyme Verification for LLMs},
  author = {Your Name},
  year = {2024},
  url = {https://github.com/yourusername/REV}
}
```

## License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## Acknowledgments

- Sequential testing algorithms adapted from PoT_Experiments
- Hyperdimensional computing core from GenomeVault
- Empirical-Bernstein bounds implementation based on statistical literature

## Contact

For questions and support, please open an issue on GitHub or contact the maintainers.