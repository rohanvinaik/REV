{
  "enhancement_plan": [
    {
      "family": "llama",
      "model_id": "llama-2-7b-chat-hf_20250902_214306",
      "model_path": "/Users/rohanvinaik/LLM_models/llama-2-7b-chat-hf",
      "analysis_type": "deep_behavioral_profiling",
      "expected_duration_hours": 24,
      "priority": "high",
      "command": "python run_rev.py \"/Users/rohanvinaik/LLM_models/llama-2-7b-chat-hf\" \\\n    --local \\\n    --memory-limit 20 \\\n    --challenges 50 \\\n    --deep-behavioral-analysis \\\n    --extract-topology \\\n    --export-topology outputs/llama_topology.json \\\n    --debug \\\n    --output outputs/llama_deep_analysis.json"
    },
    {
      "family": "gpt",
      "model_id": "gpt2_20250902_201308",
      "model_path": "/Users/rohanvinaik/LLM_models/gpt2",
      "analysis_type": "deep_behavioral_profiling",
      "expected_duration_hours": 48,
      "priority": "high",
      "command": "python run_rev.py \"/Users/rohanvinaik/LLM_models/gpt2\" \\\n    --local \\\n    --memory-limit 20 \\\n    --challenges 50 \\\n    --deep-behavioral-analysis \\\n    --extract-topology \\\n    --export-topology outputs/gpt_topology.json \\\n    --debug \\\n    --output outputs/gpt_deep_analysis.json"
    },
    {
      "family": "mistral",
      "model_id": "mistral_for_colab_20250902_214357",
      "model_path": "/Users/rohanvinaik/LLM_models/mistral_for_colab",
      "analysis_type": "deep_behavioral_profiling",
      "expected_duration_hours": 48,
      "priority": "medium",
      "command": "python run_rev.py \"/Users/rohanvinaik/LLM_models/mistral_for_colab\" \\\n    --local \\\n    --memory-limit 20 \\\n    --challenges 50 \\\n    --deep-behavioral-analysis \\\n    --extract-topology \\\n    --export-topology outputs/mistral_topology.json \\\n    --debug \\\n    --output outputs/mistral_deep_analysis.json"
    },
    {
      "family": "yi",
      "model_id": "yi-34b_20250902_214915",
      "model_path": "/Users/rohanvinaik/LLM_models/yi-34b",
      "analysis_type": "deep_behavioral_profiling",
      "expected_duration_hours": 48,
      "priority": "medium",
      "command": "python run_rev.py \"/Users/rohanvinaik/LLM_models/yi-34b\" \\\n    --local \\\n    --memory-limit 20 \\\n    --challenges 50 \\\n    --deep-behavioral-analysis \\\n    --extract-topology \\\n    --export-topology outputs/yi_topology.json \\\n    --debug \\\n    --output outputs/yi_deep_analysis.json"
    }
  ],
  "topology_schema": {
    "topology_library": {
      "version": "1.0",
      "created": "2025-09-02T22:52:42.963822",
      "description": "Deep architectural topology for model families",
      "families": {},
      "sample_schema": {
        "family": "llama",
        "reference_model": "llama-2-7b-hf",
        "analysis_duration_hours": 24,
        "total_layers": 32,
        "restriction_sites": [
          {
            "layer": 1,
            "divergence_delta": 0.1038,
            "percent_change": 32.75,
            "significance": "major_behavioral_shift",
            "attack_vector_risk": "high"
          }
        ],
        "stable_regions": [
          {
            "start": 4,
            "end": 16,
            "layers": 13,
            "std_dev": 0.0063,
            "parallel_safe": true,
            "recommended_workers": 11
          }
        ],
        "behavioral_phases": [
          {
            "phase": "embedding",
            "layers": [
              0
            ],
            "avg_divergence": 0.3167,
            "description": "Input tokenization and embedding"
          }
        ],
        "optimization_hints": {
          "parallel_speedup_potential": "11x",
          "memory_per_layer_gb": 2.1,
          "critical_layers_only": [
            1,
            2,
            3,
            4
          ],
          "skip_stable_region": [
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16
          ]
        },
        "precision_targeting": {
          "large_model_strategy": "target_restriction_sites_only",
          "expected_speedup": "15-20x",
          "accuracy_retention": "95%+"
        }
      }
    }
  },
  "timestamp": "2025-09-02T22:52:42.963952"
}